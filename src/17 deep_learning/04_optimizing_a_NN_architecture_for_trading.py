# Train a Deep NN to predict Asset Price returns
# In practice, we need to explore variations of the design options outlined above because we can rarely be sure from
# the outset which network architecture best suits the data.
# In this section, we will explore various options to build a simple feedforward Neural Network to predict asset price
# returns for a one-day horizon.

import os, sys
from ast import literal_eval as make_tuple
from time import time
from pathlib import Path
from itertools import product
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from scipy.stats import spearmanr
import seaborn as sns

from sklearn.preprocessing import StandardScaler

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation

sys.path.insert(1, os.path.join(sys.path[0], ".."))
from utils import MultipleTimeSeriesCV, format_time

gpu_devices = tf.config.experimental.list_physical_devices("GPU")
if gpu_devices:
    print("Using GPU")
    tf.config.experimental.set_memory_growth(gpu_devices[0], True)
else:
    print("Using CPU")


idx = pd.IndexSlice
np.random.seed(seed=42)
sns.set_style("whitegrid")
plt.rcParams["figure.dpi"] = 300
plt.rcParams["font.size"] = 14
pd.options.display.float_format = "{:,.2f}".format

results_path = Path("../data/ch17/results")
if not results_path.exists():
    results_path.mkdir(parents=True)
checkpoint_path = results_path / "logs"

DATA_STORE = "../data/assets.h5"


if __name__ == "__main__":
    ## Create a stock return series to predict asset price moves
    # To develop our trading strategy, we use the daily stock returns for some 995 US stocks for the eight-year period
    # from 2010 to 2017, and the features developed in Chapter 12 that include volatility and momentum factors as well
    # as lagged returns with cross-sectional and sectoral rankings.
    data = pd.read_hdf("../data/12_data.h5", "model_data").dropna().sort_index()
    data.info(show_counts=True)
    outcomes = data.filter(like="fwd").columns.tolist()

    lookahead = 1
    outcome = f"r{lookahead:02}_fwd"
    X_cv = data.loc[idx[:, :"2017"], :].drop(outcomes, axis=1)
    y_cv = data.loc[idx[:, :"2017"], outcome]
    print(len(X_cv.index.get_level_values("symbol").unique()))
    X_cv.info(show_counts=True)

    ## Automate model generation
    # The following `make_model` function illustrates how to flexibly define various architectural elements for the
    # search process. The dense_layers argument defines both the depth and width of the network as a list of integers.
    # We also use dropout for regularization, expressed as a float in the range [0, 1] to define the probability that
    # a given unit will be excluded from a training iteration.

    def make_model(dense_layers, activation, dropout):
        """Creates a multi-layer perceptron model
        dense_layers: List of layer sizes; one number per layer
        """
        model = Sequential()
        for i, layer_size in enumerate(dense_layers, 1):
            if i == 1:
                model.add(Dense(layer_size, input_dim=X_cv.shape[1]))
                model.add(Activation(activation))
            else:
                model.add(Dense(layer_size))
                model.add(Activation(activation))
        model.add(Dropout(dropout))
        model.add(Dense(1))
        model.compile(loss="mean_squared_error", optimizer="Adam")
        return model

    ## Cross-validate multiple configurations with TensorFlow
    ### Train-Test Split
    # We split the data into a training set for cross-validation, and keep the last 12 months with data as holdout test:
    n_splits = 12
    train_period_length = 21 * 12 * 4
    test_period_length = 21 * 3
    cv = MultipleTimeSeriesCV(
        n_splits=n_splits,
        train_period_length=train_period_length,
        test_period_length=test_period_length,
        lookahead=lookahead,
    )

    ### Define CV Parameters
    # Now we just need to define our Keras classifier using the make_model function, set cross-validation
    # (see chapter 6 on The Machine Learning Process and following for the OneStepTimeSeriesSplit), and the parameters
    # that we would like to explore.
    # We pick several one- and two-layer configurations, relu and tanh activation functions, and different dropout
    # rates. We could also try out different optimizers (but did not run this experiment to limit what is already a
    # computationally intensive effort):
    dense_layer_opts = [(16, 8), (32, 16), (32, 32), (64, 32)]
    activation_opts = ["tanh"]
    dropout_opts = [0, 0.1, 0.2]

    # reduce mytime
    dense_layer_opts = [(64, 32)]
    dropout_opts = [0.2]

    param_grid = list(product(dense_layer_opts, activation_opts, dropout_opts))
    np.random.shuffle(param_grid)
    print(len(param_grid))

    # To trigger the parameter search, we instantiate a GridSearchCV object, define the fit_params that will be passed
    # to the Keras modelâ€™s fit method, and provide the training data to the GridSearchCV fit method:
    def get_train_valid_data(X, y, train_idx, test_idx):
        x_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]
        x_val, y_val = X.iloc[test_idx, :], y.iloc[test_idx]
        return x_train, y_train, x_val, y_val

    ic = []
    scaler = StandardScaler()
    for params in param_grid:
        dense_layers, activation, dropout = params
        for batch_size in [256]:
            print(dense_layers, activation, dropout, batch_size)
            checkpoint_dir = (
                checkpoint_path / str(dense_layers) / activation / str(dropout) / str(batch_size)
            )
            if not checkpoint_dir.exists():
                checkpoint_dir.mkdir(parents=True, exist_ok=True)
            start = time()
            for fold, (train_idx, test_idx) in enumerate(cv.split(X_cv)):
                # get train & validation data
                x_train, y_train, x_val, y_val = get_train_valid_data(
                    X_cv, y_cv, train_idx, test_idx
                )

                # scale features
                x_train = scaler.fit_transform(x_train)
                x_val = scaler.transform(x_val)

                # set up dataframes to log results
                preds = y_val.to_frame("actual")
                r = pd.DataFrame(index=y_val.groupby(level="date").size().index)

                # create model based on validation parameters
                model = make_model(dense_layers, activation, dropout)

                # cross-validate for 20 epochs
                for epoch in range(2):
                    model.fit(
                        x_train,
                        y_train,
                        batch_size=batch_size,
                        epochs=1,
                        verbose=0,
                        shuffle=True,
                        validation_data=(x_val, y_val),
                    )
                    model.save_weights((checkpoint_dir / f"ckpt_{fold}_{epoch}").as_posix())
                    preds[epoch] = model.predict(x_val).squeeze()
                    r[epoch] = (
                        preds.groupby(level="date")
                        .apply(lambda x: spearmanr(x.actual, x[epoch])[0])
                        .to_frame(epoch)
                    )
                    print(
                        format_time(time() - start),
                        f"{fold + 1:02d} | {epoch + 1:02d} | {r[epoch].mean():7.4f} | {r[epoch].median():7.4f}",
                    )
                ic.append(
                    r.assign(
                        dense_layers=str(dense_layers),
                        activation=activation,
                        dropout=dropout,
                        batch_size=batch_size,
                        fold=fold,
                    )
                )

            t = time() - start
            pd.concat(ic).to_hdf(results_path / "scores.h5", "ic_by_day")

    ### Evaluate predictive performance
    params = ["dense_layers", "dropout", "batch_size"]

    ic = pd.read_hdf(results_path / "scores.h5", "ic_by_day").drop("activation", axis=1)
    ic.info()
    print(ic.groupby(params).size())

    ic_long = pd.melt(ic, id_vars=params + ["fold"], var_name="epoch", value_name="ic")
    ic_long.info()

    ic_long = ic_long.groupby(params + ["epoch", "fold"]).ic.mean().to_frame("ic").reset_index()
    g = sns.relplot(
        x="epoch",
        y="ic",
        col="dense_layers",
        row="dropout",
        data=ic_long[ic_long.dropout > 0],
        kind="line",
    )
    g.map(plt.axhline, y=0, ls="--", c="k", lw=1)
    g.savefig("images/04_ic_lineplot.png")

    def run_ols(ic):
        ic.dense_layers = (
            ic.dense_layers.str.replace(", ", "-", regex=False)
            .str.replace("(", "", regex=False)
            .str.replace(")", "", regex=False)
        )
        data = pd.melt(ic, id_vars=params, var_name="epoch", value_name="ic")
        data.epoch = data.epoch.astype(int).astype(str).apply(lambda x: f"{int(x):02.0f}")
        model_data = pd.get_dummies(
            data.sort_values(params + ["epoch"]), columns=["epoch"] + params, drop_first=True
        ).sort_index(1)
        model_data.columns = [s.split("_")[-1] for s in model_data.columns]
        model = sm.OLS(endog=model_data.ic, exog=sm.add_constant(model_data.drop("ic", axis=1)))
        return model.fit()

    model = run_ols(ic.drop("fold", axis=1))
    print(model.summary())

    fig, ax = plt.subplots(figsize=(14, 4))
    ci = model.conf_int()
    errors = ci[1].sub(ci[0]).div(2)
    coefs = (
        model.params.to_frame("coef")
        .assign(error=errors)
        .reset_index()
        .rename(columns={"index": "variable"})
    )
    coefs = coefs[~coefs["variable"].str.startswith("date") & (coefs.variable != "const")]

    coefs.plot(
        x="variable",
        y="coef",
        kind="bar",
        ax=ax,
        color="none",
        capsize=3,
        yerr="error",
        legend=False,
        rot=0,
        title="Impact of Architecture and Training Parameters on Out-of-Sample Performance",
    )
    ax.set_ylabel("IC")
    ax.set_xlabel("")
    ax.scatter(x=np.arange(len(coefs)), marker="_", s=120, y=coefs["coef"], color="black")
    ax.axhline(y=0, linestyle="--", color="black", linewidth=1)
    ax.xaxis.set_ticks_position("none")

    ax.annotate(
        "Batch Size",
        xy=(0.02, -0.1),
        xytext=(0.02, -0.2),
        xycoords="axes fraction",
        textcoords="axes fraction",
        fontsize=11,
        ha="center",
        va="bottom",
        bbox=dict(boxstyle="square", fc="white", ec="black"),
        arrowprops=dict(arrowstyle="-[, widthB=1.3, lengthB=0.8", lw=1.0, color="black"),
    )

    ax.annotate(
        "Layers",
        xy=(0.1, -0.1),
        xytext=(0.1, -0.2),
        xycoords="axes fraction",
        textcoords="axes fraction",
        fontsize=11,
        ha="center",
        va="bottom",
        bbox=dict(boxstyle="square", fc="white", ec="black"),
        arrowprops=dict(arrowstyle="-[, widthB=4.8, lengthB=0.8", lw=1.0, color="black"),
    )

    ax.annotate(
        "Dropout",
        xy=(0.2, -0.1),
        xytext=(0.2, -0.2),
        xycoords="axes fraction",
        textcoords="axes fraction",
        fontsize=11,
        ha="center",
        va="bottom",
        bbox=dict(boxstyle="square", fc="white", ec="black"),
        arrowprops=dict(arrowstyle="-[, widthB=2.8, lengthB=0.8", lw=1.0, color="black"),
    )

    ax.annotate(
        "Epochs",
        xy=(0.62, -0.1),
        xytext=(0.62, -0.2),
        xycoords="axes fraction",
        textcoords="axes fraction",
        fontsize=11,
        ha="center",
        va="bottom",
        bbox=dict(boxstyle="square", fc="white", ec="black"),
        arrowprops=dict(arrowstyle="-[, widthB=30.5, lengthB=1.0", lw=1.0, color="black"),
    )

    sns.despine()
    fig.tight_layout()
    fig.savefig("images/04_ols_coef", dpi=300)

    ## Make Predictions
    def get_best_params(n=5):
        """Get the best parameters across all folds by daily median IC"""
        params = ["dense_layers", "activation", "dropout", "batch_size"]
        ic = pd.read_hdf(results_path / "scores.h5", "ic_by_day").drop("fold", axis=1)
        dates = sorted(ic.index.unique())
        train_period = 24 * 21
        train_dates = dates[:train_period]
        ic = ic.loc[train_dates]
        return (
            ic.groupby(params)
            .median()
            .stack()
            .to_frame("ic")
            .reset_index()
            .rename(columns={"level_4": "epoch"})
            .nlargest(n=n, columns="ic")
            .drop("ic", axis=1)
            .to_dict("records")
        )

    def generate_predictions(dense_layers, activation, dropout, batch_size, epoch):
        data = pd.read_hdf("../data/12_data.h5", "model_data").dropna().sort_index()
        outcomes = data.filter(like="fwd").columns.tolist()
        X_cv = data.loc[idx[:, :"2017"], :].drop(outcomes, axis=1)
        # input_dim = X_cv.shape[1]
        y_cv = data.loc[idx[:, :"2017"], "r01_fwd"]

        scaler = StandardScaler()
        predictions = []

        do = "0" if str(dropout) == "0.0" else str(dropout)
        checkpoint_dir = (
            checkpoint_path / str(dense_layers) / activation / str(do) / str(batch_size)
        )

        for fold, (train_idx, test_idx) in enumerate(cv.split(X_cv)):
            x_train, y_train, x_val, y_val = get_train_valid_data(X_cv, y_cv, train_idx, test_idx)
            x_val = scaler.fit(x_train).transform(x_val)
            model = make_model(make_tuple(dense_layers), activation, dropout)
            status = model.load_weights((checkpoint_dir / f"ckpt_{fold}_{epoch}").as_posix())
            status.expect_partial()
            predictions.append(pd.Series(model.predict(x_val).squeeze(), index=y_val.index))
        return pd.concat(predictions)

    best_params = get_best_params()
    predictions = []
    for i, params in enumerate(best_params):
        predictions.append(generate_predictions(**params).to_frame(i))

    predictions = pd.concat(predictions, axis=1)
    print(predictions.info())
    predictions.to_hdf(results_path / "test_preds.h5", "predictions")

    ### How to further improve the results
    # The relatively simple architecture yields some promising results. To further improve performance, you can
    # - First and foremost, add new features and more data to the model
    # - Expand the set of architectures to explore, including more or wider layers
    # - Inspect the training progress and train for more epochs if the validation error continued to improve at 50 epochs
    # Finally, you can use more sophisticated architectures, including Recurrent Neural Networks (RNN) and Convolutional
    # Neural Networks that are well suited to sequential data, whereas vanilla feedforward NNs are not designed to
    # capture the ordered nature of the features.
