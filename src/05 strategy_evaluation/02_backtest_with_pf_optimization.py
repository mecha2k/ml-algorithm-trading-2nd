# MeanReversion backtest with Portfolio Optimization
# In the chapter 04, we introduced `zipline` to simulate the computation of alpha factors from trailing
# cross-sectional market, fundamental, and alternative data. Now we will exploit the alpha factors to derive and act
# on buy and sell signals using the custom MeanReversion factor developed in the last chapter.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sys
import logbook
import warnings

from pytz import UTC
from logbook import (
    NestedSetup,
    NullHandler,
    Logger,
    StreamHandler,
    StderrHandler,
    INFO,
    WARNING,
    DEBUG,
    ERROR,
)

from zipline import run_algorithm
from zipline.api import (
    attach_pipeline,
    date_rules,
    time_rules,
    get_datetime,
    order_target_percent,
    pipeline_output,
    record,
    schedule_function,
    get_open_orders,
    calendars,
    set_commission,
    set_slippage,
)
from zipline.finance import commission, slippage
from zipline.pipeline import Pipeline, CustomFactor
from zipline.pipeline.factors import Returns, AverageDollarVolume

# from pypfopt.efficient_frontier import EfficientFrontier
# from pypfopt import risk_models, objective_functions
# from pypfopt import expected_returns
# from pypfopt.exceptions import OptimizationError
from pyfolio.utils import extract_rets_pos_txn_from_zipline

sns.set_style("whitegrid")
plt.rcParams["figure.dpi"] = 300
plt.rcParams["font.size"] = 12
warnings.filterwarnings("ignore")

MONTH = 21
YEAR = 12 * MONTH
N_LONGS = 50
N_SHORTS = 50
MIN_POS = 5
VOL_SCREEN = 1000


class MeanReversion(CustomFactor):
    """Compute ratio of the latest monthly return to 12m average,
    normalized by std dev of monthly returns"""

    inputs = [Returns(window_length=MONTH)]
    window_length = YEAR

    def compute(self, today, assets, out, monthly_returns):
        df = pd.DataFrame(monthly_returns)
        factor = df.iloc[-1].sub(df.mean()).div(df.std())
        out[:] = factor


## Create Pipeline
# The Pipeline created by the `compute_factors()` method returns a table with a long and a short column
# for the 25 stocks with the largest negative and positive deviations of their last monthly return from its annual
# average, normalized by the standard deviation. It also limited the universe to the 500 stocks with the highest
# average trading volume over the last 30 trading days.
def compute_factors():
    """Create factor pipeline incl. mean reversion,
    filtered by 30d Dollar Volume; capture factor ranks"""
    mean_reversion = MeanReversion()
    dollar_volume = AverageDollarVolume(window_length=30)
    return Pipeline(
        columns={
            "longs": mean_reversion.bottom(N_LONGS),
            "shorts": mean_reversion.top(N_SHORTS),
            "ranking": mean_reversion.rank(ascending=False),
        },
        screen=dollar_volume.top(VOL_SCREEN),
    )


# `Before_trading_start()` ensures the daily execution of the pipeline and the recording of the results, including
# the current prices.
def before_trading_start(context, data):
    """Run factor pipeline"""
    context.factor_data = pipeline_output("factor_pipeline")
    record(factor_data=context.factor_data.ranking)
    assets = context.factor_data.index
    record(prices=data.current(assets, "price"))


## Set up Rebalancing
# The new `rebalance()` method submits trade orders to the `exec_trades()` method for the assets flagged for long and
# short positions by the pipeline with equal positive and negative weights.
# It also divests any current holdings that are no longer included in the factor signals:
def exec_trades(data, positions):
    """Place orders for assets using target portfolio percentage"""
    for asset, target_percent in positions.items():
        if data.can_trade(asset) and not get_open_orders(asset):
            order_target_percent(asset, target_percent)


def rebalance(context, data):
    """Compute long, short and obsolete holdings; place orders"""
    factor_data = context.factor_data
    assets = factor_data.index

    longs = assets[factor_data.longs]
    shorts = assets[factor_data.shorts]

    divest = context.portfolio.positions.keys() - longs.union(shorts)
    exec_trades(data, positions={asset: 0 for asset in divest})
    log.info("{} | {:11,.0f}".format(get_datetime().date(), context.portfolio.portfolio_value))

    # get price history
    prices = data.history(
        assets, fields="price", bar_count=252 + 1, frequency="1d"  # for 1 year of returns
    )

    # get optimal weights if sufficient candidates
    if len(longs) > MIN_POS and len(shorts) > MIN_POS:
        try:
            long_weights = optimize_weights(prices.loc[:, longs])
            short_weights = optimize_weights(prices.loc[:, shorts], short=True)

            exec_trades(data, positions=long_weights)
            exec_trades(data, positions=short_weights)
        except Exception as e:
            log.warn("{} {}".format(get_datetime().date(), e))
    # exit remaining positions
    divest_pf = {asset: 0 for asset in context.portfolio.positions.keys()}
    exec_trades(data, positions=divest_pf)


def optimize_weights(prices, short=False):
    returns = expected_returns.mean_historical_return(prices=prices, frequency=252)
    cov = risk_models.sample_cov(prices=prices, frequency=252)

    # get weights that maximize the Sharpe ratio
    ef = EfficientFrontier(
        expected_returns=returns, cov_matrix=cov, weight_bounds=(0, 1), solver="SCS"
    )
    ef.max_sharpe()
    if short:
        return {asset: -weight for asset, weight in ef.clean_weights().items()}
    else:
        return ef.clean_weights()


## Initialize Backtest
# The `rebalance()` method runs according to `date_rules` and `time_rules` set by the `schedule_function()` utility
# at the beginning of the week, right after `market_open` as stipulated by the built-in `US_EQUITIES` calendar
# (see docs for details on rules).
# You can also specify a trade commission both in relative terms and as a minimum amount. There is also an option to
# define slippage, which is the cost of an adverse change in price between trade decision and execution
def initialize(context):
    """Setup: register pipeline, schedule rebalancing,
    and set trading params"""
    attach_pipeline(compute_factors(), "factor_pipeline")
    schedule_function(
        rebalance, date_rules.week_start(), time_rules.market_open(), calendar=calendars.US_EQUITIES
    )
    set_commission(us_equities=commission.PerShare(cost=0.00075, min_trade_cost=0.01))
    set_slippage(us_equities=slippage.VolumeShareSlippage(volume_limit=0.0025, price_impact=0.01))


if __name__ == "__main__":
    format_string = "[{record.time: %H:%M:%S.%f}]: {record.level_name}: {record.message}"
    zipline_logging = NestedSetup(
        [
            NullHandler(level=DEBUG),
            StreamHandler(sys.stdout, format_string=format_string, level=INFO),
            StreamHandler(sys.stdout, format_string=format_string, level=WARNING),
            StreamHandler(sys.stderr, level=ERROR),
        ]
    )
    zipline_logging.push_application()
    log = Logger("Algorithm")

    start = pd.Timestamp("2013-01-01", tz=UTC)
    end = pd.Timestamp("2017-01-01", tz=UTC)
    capital_base = 1e7

    # The algorithm executes upon calling the `run_algorithm()` function and returns the backtest performance `DataFrame`.
    backtest = run_algorithm(
        start=start,
        end=end,
        initialize=initialize,
        before_trading_start=before_trading_start,
        bundle="quandl",
        capital_base=capital_base,
    )

    # The `extract_rets_pos_txn_from_zipline` utility provided by `pyfolio` extracts the data used to compute
    # performance metrics.
    returns, positions, transactions = extract_rets_pos_txn_from_zipline(backtest)

    with pd.HDFStore("../data/backtests.h5") as store:
        store.put("returns/pf_opt", returns)
        store.put("transactions/pf_opt", transactions)

    with pd.HDFStore("backtests.h5") as store:
        returns_pf = store["returns/pf_opt"]
        tx_pf = store["transactions/pf_opt"]
        returns_ew = store["returns/equal_weight"]
        tx_ew = store["transactions/equal_weight"]

    fig, axes = plt.subplots(nrows=2, figsize=(14, 6))
    returns.add(1).cumprod().sub(1).plot(ax=axes[0], title="Cumulative Returns")
    transactions.groupby(transactions.dt.dt.day).txn_dollars.sum().cumsum().plot(
        ax=axes[1], title="Cumulative Transactions"
    )
    fig.tight_layout()
    plt.savefig("images/02-01.png", bboxinches="tight")

    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 8), sharey="col")
    returns_ew.add(1).cumprod().sub(1).plot(
        ax=axes[0][0], title="Cumulative Returns - Equal Weight"
    )
    returns_pf.add(1).cumprod().sub(1).plot(
        ax=axes[1][0], title="Cumulative Returns - Mean-Variance Optimization"
    )
    tx_ew.groupby(tx_ew.dt.dt.day).txn_dollars.sum().cumsum().plot(
        ax=axes[0][1], title="Cumulative Transactions - Equal Weight"
    )
    tx_pf.groupby(tx_pf.dt.dt.day).txn_dollars.sum().cumsum().plot(
        ax=axes[1][1], title="Cumulative Transactions - Mean-Variance Optimization"
    )
    fig.suptitle("Equal Weight vs Mean-Variance Optimization", fontsize=16)
    fig.tight_layout()
    fig.subplots_adjust(top=0.9)
    plt.savefig("images/02-02.png", bboxinches="tight")
